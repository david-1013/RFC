{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "nidx = 1\n",
    "label = 'xe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_split = 1\n",
    "fold_seed = 5295; \n",
    "s= 0; e = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GN = 0.025\n",
    "IN_WT = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH =   ''# '../input/nrc-inputs/'\n",
    "TRAIN_FILE = 'NIJ_s_Recidivism_Challenge_Training_Dataset.csv'\n",
    "TEST_FILE = 'NIJ_s_Recidivism_Challenge_Test_Dataset1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset#,# random_split\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mish(x):\n",
    "    return (x * torch.tanh(F.softplus(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x, scaler = StandardScaler):\n",
    "    return pd.DataFrame( scaler().fit_transform(x), \n",
    "                            index = x.index, columns = x.columns)#, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(t):\n",
    "    return t.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 8\n",
    "alt_weight = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP2(pl.LightningModule):\n",
    "    def __init__(self, input_size, embedding_size = 32, \n",
    "                 input_dropout = 0.2, final_dropout = 0.5,\n",
    "                     lr = 3e-4, weight_decay = 1e-3, prelu_init = 0.25,\n",
    "                        n_outputs = 1):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.embedding_size = embedding_size\n",
    "        self.weight_decay = weight_decay\n",
    "        self.prelu_init = prelu_init\n",
    "        \n",
    "        self.input_dropout = nn.Dropout(input_dropout)\n",
    "        \n",
    "        g = 8\n",
    "        self.layer1 = nn.Linear(input_size, embedding_size)\n",
    "        self.layer1_norm = nn.GroupNorm(g, embedding_size)\n",
    "        self.dropout1 = nn.Dropout(final_dropout)\n",
    "        \n",
    "        self.layer2 = nn.Linear(embedding_size, embedding_size)\n",
    "        self.layer2_norm = nn.GroupNorm(g, embedding_size)\n",
    "        self.dropout2 = nn.Dropout(final_dropout)\n",
    "        \n",
    "        self.a1 = nn.LeakyReLU(0.25)\n",
    "        self.a2 = nn.LeakyReLU(0.25)\n",
    "\n",
    "        \n",
    "        self.final = nn.Linear(embedding_size, n_outputs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xn = x + GN * torch.randn( x.shape )\n",
    "        m1 = self.a1(self.layer1_norm(self.layer1(self.input_dropout( IN_WT * xn))))\n",
    "        m2 = self.a2(self.layer2_norm(self.layer2(self.dropout1(m1))))\n",
    "        out = self.final(self.dropout2(m2))\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, ID = batch\n",
    "       #  y = y.view(y.shape[0], -1)\n",
    "\n",
    "        output = self.forward(x)\n",
    "        loss = ( ( F.mse_loss(y, output) * 0.30\n",
    "                    + F.mse_loss(y[:, -4:], output[:, -4:]) * 0.20 ) * alt_weight\n",
    "                        + F.mse_loss(y[:, -1], output[:, -1] ) * 1.00 )\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, \n",
    "                 prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, ID = batch\n",
    "#         y = y.view(y.shape[0], -1)\n",
    "        output = self.forward(x)\n",
    "    \n",
    "        is_test = y[:, -1] < 0\n",
    "        \n",
    "        holdout = output[~is_test]\n",
    "        scored_y = y[~is_test]\n",
    "        test = output[is_test]\n",
    "        \n",
    "#         print(scored_y.shape)\n",
    "#         print(holdout.shape)\n",
    "        \n",
    "\n",
    "        loss = ( F.mse_loss(scored_y, holdout) * 0.0\n",
    "                    + F.mse_loss(scored_y[:, -4:], holdout[:, -4:]) * 0.0\n",
    "                        + F.mse_loss(scored_y[:, -1], holdout[:, -1] ) * 1.00 )\n",
    "        self.log('holdout_loss', loss, on_step=False, on_epoch=True, \n",
    "                 prog_bar=True, logger=True)\n",
    "        all_preds.append(pd.Series(clean(holdout[:, -1]), index = clean(ID[~is_test])))\n",
    "        all_tests.append(pd.Series(clean(test[:, -1]), index = clean(ID[is_test])))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, ID = batch\n",
    "        output = self.forward(x)\n",
    "        return output\n",
    "\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr = self.lr,\n",
    "                                             weight_decay = self.weight_decay )\n",
    "        return optimizer\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NRCDataset(Dataset):\n",
    "\n",
    "    def __init__(self, features, targets, indices, test_indices = None):\n",
    "#         print(targets.shape)\n",
    "        self.y = targets.iloc[indices]\n",
    "        self.x = features.reindex(self.y.index)\n",
    "        \n",
    "        if test_indices is not None:\n",
    "            \n",
    "            self.y = pd.concat( (self.y,\n",
    "                                     pd.DataFrame( -1 * np.ones((len(test_indices), len(targets.columns)) ), \n",
    "                                                      index = test_indices, columns = targets.columns) ) )\n",
    "#             print(self.y)\n",
    "            self.x = pd.concat( ( self.x, features.reindex(test_indices) ) )\n",
    "    \n",
    "    \n",
    "#             idxs = np.arange(0, len(self.x))\n",
    "#             random.shuffle(idxs)\n",
    "            \n",
    "#             self.y = x.iloc[idxs]\n",
    "    \n",
    "#             print(self.x)\n",
    "        \n",
    "        self.indices = self.y.index.to_list()\n",
    "        \n",
    "        # this is a weird bug -- but it's basically gaussian noise at inference time\n",
    "#         self.x = norm(self.x)\n",
    "# fixed\n",
    " \n",
    "        self.x = self.x.values.astype(np.float32)\n",
    "        self.y = self.y.values.astype(np.float32)  \n",
    "\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index], self.indices[index] )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xe = pd.read_csv(PATH + 'xe.csv', index_col = 'ID')\n",
    "# xe2 = pd.read_csv(PATH + 'xe2.csv', index_col = 'ID')\n",
    "y = pd.read_csv(PATH + TRAIN_FILE, index_col = 'ID')#['Recidivism_Arrest_Year1']\n",
    "test = pd.read_csv(PATH + TEST_FILE, index_col = 'ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv(PATH + 'all_targets.csv', index_col = 'ID').fillna(0)\\\n",
    "    .drop(columns = 'Avg_Days_per_DrugTest_1')\n",
    "y = y[sorted([c for c in y.columns if 'Recidivism' not in c]) +  \\\n",
    "                  ['Recidivism_Arrest_Year2', 'Recidivism_Arrest_Year3',\n",
    "                          'Recidivism_Within_3years',\n",
    "                    'Recidivism_Arrest_Year1'  ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xe = norm(xe)\n",
    "# xe2 = norm(xe2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = norm(y,  MinMaxScaler\n",
    "        ).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = []; \n",
    "for i in range(500):\n",
    "    folds.extend(list(StratifiedKFold(random_state = i + fold_seed, shuffle = True)\n",
    "                              .split(np.zeros(len(y)), y.iloc[:,-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = eval(label); \n",
    "\n",
    "network = [MLP2, MLP2,]\n",
    "layers = [2, 2,]\n",
    "dims = [384, 640,] \n",
    "wd = [0.5] * 2\n",
    "\n",
    "batch_size = [256] * 2\n",
    "drop_last = [True] * 2\n",
    "\n",
    "epochs = [60] * 2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WORKERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14849.3s elapsed for 80 folds\n",
      " through epoch 40\n",
      " -0.08: 0.1874\n",
      " -0.15: 0.1873\n",
      "\n",
      " through epoch 60\n",
      " -0.08: 0.1876\n",
      " -0.15: 0.1880\n",
      "\n",
      "\n",
      "median: 0.1873\n",
      "40 -0.08: 0.18706\n",
      "40 -0.15: 0.18708\n",
      "60 -0.08: 0.18739\n",
      "60 -0.15: 0.18771\n",
      "\n",
      "median: 0.18706\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "start = time.time()\n",
    "\n",
    "final_preds = defaultdict(list)\n",
    "final_test_preds = defaultdict(list)\n",
    "\n",
    "wtg_scores = defaultdict(list)\n",
    "median_scores = []\n",
    "wtg_median_scores = defaultdict(list)\n",
    "\n",
    "for fold in folds[s:e]:\n",
    "\n",
    "    test_indices = list(set(features.index)-set(y.index) )\n",
    "    train_data = NRCDataset(features, y, fold[0])\n",
    "    holdout_data = NRCDataset(features, y, fold[1], test_indices)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size = batch_size[nidx], shuffle=True, \n",
    "                             num_workers = N_WORKERS, \n",
    "                                                      drop_last = drop_last[nidx], pin_memory = True)\n",
    "    holdout_loader = DataLoader(holdout_data, batch_size = 32768, \n",
    "                             num_workers = N_WORKERS, pin_memory = True)\n",
    "    \n",
    "    mlp = network[nidx](len(train_data[0][0]), dims[nidx], weight_decay = wd[nidx],\n",
    "                               n_outputs = y.shape[1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    all_preds = []; all_tests = []\n",
    "    trainer = pl.Trainer(min_epochs=epochs[nidx], max_epochs=epochs[nidx])#gpus = 1 if )\n",
    "    trainer.fit(mlp, train_loader, holdout_loader)\n",
    "    \n",
    "    \n",
    "    def expAvg(x, decay, final = 20):\n",
    "        x = x[:final]\n",
    "        wts = np.exp( - decay * np.arange(0, len(x)) )\n",
    "        return (x.values * wts).sum() / wts.sum()\n",
    "    \n",
    "\n",
    "    clear_output(wait = True); \n",
    "    print('{:.1f}s elapsed for {} folds'.format(time.time() - start, 1 + len(median_scores)))\n",
    "\n",
    "    combined_preds = pd.concat(all_preds)\n",
    "    combined_tests = pd.concat(all_tests)\n",
    "\n",
    "#     test_preds = combined_preds[combined_preds.index.isin(test_indices)]\n",
    "#     preds = combined_preds[~combined_preds.index.isin(test_indices)]\n",
    "    \n",
    "#     preds = preds.iloc[preds.index.nunique()*0:preds.index.nunique()*1000]\n",
    "\n",
    "    for last_epoch in [40, 60]:\n",
    "        print(' through epoch {}'.format(last_epoch))\n",
    "        for decay in [  -0.08, -0.15]:\n",
    "            avg_pred = combined_preds.groupby(combined_preds.index).apply(\n",
    "                            expAvg, decay, last_epoch).clip(0, 1)\n",
    "            score = mean_squared_error( y.reindex(avg_pred.index).iloc[:, -1], avg_pred )\n",
    "            print(' {:.2f}: {:.4f}'.format(decay, score ))\n",
    "            wtg_scores['{} {:.2f}'.format(last_epoch, decay)].append(score)\n",
    "        print()\n",
    "\n",
    "    print()\n",
    "    \n",
    "    avg_pred = combined_preds.groupby(combined_preds.index).median()\n",
    "    score = mean_squared_error( y.reindex(avg_pred.index).iloc[:, -1], avg_pred )\n",
    "    print('median: {:.4f}'.format(score ))\n",
    "    median_scores.append(score)\n",
    "    \n",
    "    \n",
    "    for d, s in wtg_scores.items():\n",
    "        print('{}: {:.5f}'.format(d, np.mean(s)))\n",
    "\n",
    "    print()\n",
    "\n",
    "    print('median: {:.5f}'.format(np.mean(median_scores)))\n",
    "\n",
    "\n",
    "\n",
    "    for s in [ -0.08, -0.15]:\n",
    "        for e in [40, 60]:\n",
    "            final_preds['mean{}_{:.2f}'.format(e, -s)].append(combined_preds.groupby(combined_preds.index).apply(expAvg, s, e))\n",
    "            final_test_preds['mean{}_{:.2f}'.format(e, -s)].append(combined_tests.groupby(combined_tests.index).apply(expAvg, s, e))\n",
    "            \n",
    "#     final_preds['median'].append(combined_preds.groupby(combined_preds.index).median())\n",
    "#     final_preds['all'].append(combined_preds);\n",
    "\n",
    "#     final_test_preds['median'].append(combined_tests.groupby(combined_tests.index).median())\n",
    "#     final_test_preds['all'].append(combined_tests);\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 -0.08: 0.18706\n",
      "40 -0.15: 0.18708\n",
      "60 -0.08: 0.18739\n",
      "60 -0.15: 0.18771\n",
      "\n",
      "median: 0.18706\n"
     ]
    }
   ],
   "source": [
    "for d, s in wtg_scores.items():\n",
    "    print('{}: {:.5f}'.format(d, np.mean(s)))\n",
    "\n",
    "print()\n",
    "\n",
    "print('median: {:.5f}'.format(np.mean(median_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_preds = dict([(k, pd.concat(v)) for k, v in final_preds.items()])\n",
    "stacked_tests = dict([(k, pd.concat(v)) for k, v in final_test_preds.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('out/'): os.mkdir('out')\n",
    "# if not os.path.exists('out_test/'): os.mkdir('out_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(final_preds['mean']))\n",
    "[ stacked_preds[k].to_csv('out/NN_{}_{}layer_{}ch_f{}*{}_{}.csv'.format(\n",
    "    label, layers[nidx], dims[nidx], fold_seed, len(median_scores), k))\n",
    "         for k in stacked_preds.keys() ]\n",
    "\n",
    "[ stacked_tests[k].to_csv('out/NN_{}_{}layer_{}ch_f{}*{}_{}_test.csv'.format(\n",
    "    label, layers[nidx], dims[nidx], fold_seed, len(median_scores), k))\n",
    "         for k in stacked_tests.keys() ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
